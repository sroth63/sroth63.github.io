<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <p>Notes sur <em>La dictature des algorithmes</em> de Lê Nguyen Hoang et Jean-Lou Fourquet</p>
    <h2>I Les IA de recommandation</h2>
    <h3>I.1 L'attention</h3>
    <ul>
      <li>Étage individuel : système 1 (pensée instinctive) / système 2 (pensée raisonnée) de Kahneman. Résultat de l'évolution, régions cérébrales distinctes. La métacognition permet de manipuler l'attention.</li>
      <li>En situation d'urgence : dans bcp de cultures traditionnelles, on écoute les anciens. Dans les sociétés modernes, les anciens ont été remplacés par les journalistes.</li>
      <li>
        <p>Médias traditionnels : le choix des sujets est un très grand pouvoir :</p>
        <ul>
          <li>Censure</li>
          <li>Soft power / fictions pour imposer une vision du monde (ex : Rocky)</li>
          <li>Mauvaise priorisation des sujets, consciente ou non (ex : nucléaire / charbon)</li>
          <li>Fabrique du consentement (Chomsky) : l'indépendance du journalisme occidental est illusoire. On sélectionne les journalistes qui "pensent comme il faut".</li>
        </ul>
      </li>
    </ul>
    <h3>I.2 Les IA de recommandation</h3>
    <ul>
      <li>Ont largement remplacé Google Search (depuis 2016, plus de vues YouTube que de recherches Google). Les vues sur YouTube et TikTok se font surtout depuis des smartphones => les utilisateurs font très peu de recherches (trop pénible) et laissent faire les IAR. Les IAR sont utilisés par une grande partie de la population pour s'informer.</li>
      <li>IAR = rédacteurs en chefs surhumains qui peuvent faire le tri entre des quantités astronomiques d'informations</li>
      <li>Les IAR ont très souvent pour objectif d'extraire et d'exploiter l'attention des utilisateurs</li>
      <li>Personnalisation extrême, surhumaine permise par les IAR => on ne peut pas se baser sur un ressenti individuel pour les comprendre. Création de cercles vicieux idéologiques.</li>
      <li>
        <p>Économie de l'attention</p>
        <ul>
          <li>TikTok : exploite le système 1, les dirigeants de l'entreprise ont un pouvoir énorme</li>
          <li>Beaucoup de réseaux sociaux ont cherché à copier TT</li>
        </ul>
      </li>
    </ul>
    <h3>I.3 Les IAR sont l'arme informationnelle ultime</h3>
    <ul>
      <li>Les IAR ont un objectif apparemment neutre, mais qui a des conséquences sociétales / politiques (ex : Trump 6x plus recommandé que Clinton sur YT lors de la campagne de 2016)</li>
      <li>
        <p>Utilisation autoritaire</p>
        <ul>
          <li>Musk a fait penché l'IAR de Twitter vers la droite</li>
          <li>Chine : Internet contrôllé à des fins politiques par 2 millions d'employés et 20 millions de volontaires</li>
        </ul>
      </li>
      <li>
        <p>Manipulation des IAR :</p>
        <ul>
          <li>Faux comptes : Facebook supprime environ 7 milliards de faux comptes par an</li>
          <li>Créer de la division / polarisation (ex : agences de désinformation russes pendant Black Lives Matters)</li>
        </ul>
      </li>
      <li>
        <p>Les réseaux sociaux sont des puissances politiques</p>
        <ul>
          <li>Facebook : "conseil de surveillance" pour modérer les contenus</li>
          <li>2021 : l'Australie a régulé Google et FB pour qu'ils payent les entreprises de presse</li>
          <li>2023 : tentative de régulation au Canada, ça a + ou - marché pour Google mais pas pour FB</li>
        </ul>
      </li>
      <li>
        <p>TikTok : réseau social au service d'un État</p>
        <ul>
          <li>arme de destruction massive utilisée dans la guerre cognitive</li>
          <li>interdit en Chine (remplacé par Douyin dont les recommandations n'ont rien à voir). Manipulation manuelle des recommandations sur les Ouighours.</li>
          <li>IAR = banque centrale, attention = monnaie. TikTok n'a pas besoin de payer les influenceurs pour qu'ils tiennent le bon discours, il suffit de modifier l'IAR</li>
        </ul>
      </li>
    </ul>
    <h3>I.4 Conséquences des IAR</h3>
    <ul>
      <li>Suicide de Molly (fille de 14 ans) : la justice britannique a conclu à la responsabilité des plateformes</li>
      <li>Conséquences individuelles : plus largement, épidémie de maladies mentales. Aux US, 30% des adolescentes révèlent avoir déjà sérieusement envisagé de se suicider.</li>
      <li>
        <p>Conséquences civilisationnelles :</p>
        <ul>
          <li>Utilisation pour les appels à la haine. La colère est un sentiment efficace pour rendre un contenu viral. Ex des contenus anti-Rohingya sur FB (accusation de génocide). On est davantage confrontés à des avis contraires sur Internet que dans la "vraie vie", mais cela aggrave la polarisation émotionnelle (caricatures agaçantes du clan opposé).</li>
          <li>Univers informationnels parallèles / filter bubbles (ex : anti vax)</li>
          <li>Les créateurs modifient leurs contenus pour avoir plus d'attention, sans se préoccuper des conséquences éthiques</li>
          <li>Mute news (sujets peu attractifs donc peu recommandés) : climat, droits humains, santé mentale, cybercriminalité, IAR,…</li>
        </ul>
      </li>
    </ul>
    <h3>I.5 Les IA en général</h3>
    <ul>
      <li>Armes autonomes : danger majeur pour le maintien de la paix, car elles pourraient être très peu chères, et elles sont pas réglementées pour l'instant. Elles pourraient nuire aux stratégie de dissusasion nucléaire.</li>
      <li>IA génératives : facilitent la désinformation / manipulation</li>
      <li>Conséquences sur le marché du travail : précarisation, augmentation des inégalités de richesse, fin du travail ?</li>
      <li>IA financières : Aladdin controlle 21 000 milliards de $ d'actifs (4x budget annuel des US)</li>
      <li>Quelques applications bénéfiques : santé, smart grids</li>
    </ul>
    <h3>I.6 Les Big Techs, nouveaux marchands de doute</h3>
    <ul>
      <li>"Il y a d'autres causes" : ajouter des voix discordantes, suggérer d'autres causes.</li>
      <li>
        <p>"Il n'y a pas de certitude absolue" : insister sur de possibles facteurs de confusion</p>
        <ul>
          <li>"Corrélation n'est pas causalité"</li>
          <li>Pas de certitude absolue => il ne faut pas réglementer : fallacieux, il faut penser de façon probabiliste</li>
          <li>Principe de précaution : les recommandations de régulation des RS sont peu risquées et peu coûteuses, donc ça vaut le coup de les adopter même si on n'est pas sûr à 100% des risques. C'est ce qu'on fait en médecine : on n'a pas attendu de tout savoir sur le Covid avant d'agir.</li>
        </ul>
      </li>
      <li>"Ne sacrifions pas les conséquences positives" : souvent fallacieux, il faut correctement évaluer la balance bénéfices / risques</li>
      <li>
        <p>Corruption des scientifiques</p>
        <ul>
          <li>Seuls les Big Techs ont les données nécessaires à la recherche</li>
          <li>Les Big Techs financent massivement la recherche en informatique</li>
          <li>Les scientifiques critiques sont dénigrés</li>
        </ul>
      </li>
      <li>Corruption des politiques : exemple de la tentative d'interdiction de TikTok aux US</li>
      <li>Contrairement au tabac, il n'y a pas qu'un seul risque potentiel (santé) mais plusieurs (santé mentale, polarisation, appels à la haine,…). Il est très peu probable qu'aucun de ces risques ne soit avéré.</li>
      <li>Manque de méfiance envers les Big Techs. Exemple : Le Monde a écrit un article sur les opinions de Yann le Cun sans préciser qu'il travaille chez FB. Ce serait scandaleux d'inviter le directeur de Nestlé parler du sucre sans dire qui il est.</li>
    </ul>
    <h3>I.7 Centralisation ou décentralisation ?</h3>
    <ul>
      <li>Risque de chaos décentralisé : amplifié par la possibilité de plus en plus grande qu'un petit groupe de personnes fassent des cyberattaques, créent des virus,… On observe déjà un manque de coopération entre États (ex : changement climatique). Mais tout n'est pas à rejeter dans les systèmes décentralisés : open source, marché libre,… mais dans ces cas, il y a toujours une forme de centralisation.</li>
      <li>Risque d'autoritarisme centralisé : les dicateurs sont facilement influencés / manipulés</li>
      <li>On retrouve cette tension dans le domaine informationnel : liberté d'expression / censure. La liberté d'expression et d'amplification entraîne souvent un capitalisme de l'information (médias détenus par des milliardaires)</li>
      <li>Société = super-organisme ? Et notre bien-être dépend en partie de la santé du super-organisme => il faut améliorer son système nerveux</li>
      <li>IAR = raccourcis de pensée / biais cognitifs du super-organisme ? Elles choisissent quelles infos prioriser, mais de façon nocive</li>
      <li>L'enjeu est d'extraire la sagesse des foules. Selon Hawkins (neuroscientifique), c'est ce qui se passe dans nos cerveaux : des "colonnes" de neurones "votent" pour prendre des décisions</li>
      <li>IAR (bonnes ou mauvaises) => perte d'autonomie ? Pas clair, on était sans doute moins autonomes / capables avant Internet, et les IAR peuvent agir pour notre autonomie</li>
      <li>Idéalement : décentraliser la conception, centraliser la mise en vigueur ? C'est ce qui se passe pour les lois dans les États de droit.</li>
    </ul>
    <h2>II Démocratie algorithmique</h2>
    <h3>II.1 La loi</h3>
    <ul>
      <li>La loi est une sorte d'algorithme</li>
      <li>Mais qui est fait pour être appliqué par des humains</li>
      <li>L'algorithmisation de la loi permet davantage d'égalité, la rend vérifiable et corrigible : forme d'open-source !</li>
      <li>Pb : loi satisfaisante => loi longue et complexe => la loi ne peut pas être connue par tous les citoyens, voire pas entièrement par les juges</li>
      <li>En pratique, la loi est seulement en partie algorithmique, et les juges ont une marge de manœuvre</li>
      <li>Autre pb : l'open-source permet de facilement trouver des failles dans la loi et de les exploiter (mais l'opacité pose aussi bcp de pb). Compromis : rendre le code ouvert uniquement aux chercheurs / entreprises de cyber ?</li>
    </ul>
    <h3>II.2 La démocratie</h3>
    <ul>
      <li>En général, il n'y a pas de mécanisme satisfaisant permettant aux citoyens d'attirer l'attention du gvt sur un point particulier. Exception : votations populaires en Suisse.</li>
      <li>Nombreuses lois sur l'information : liberté de la presse mais injure, diffamation, incitation à la haine interdites, limitation du temps de parole, lois sur la propriété intellectuelle</li>
      <li>Les lois sur le numérique (DMA, DSA, RGPD,…) sont peu appliquées => il faut une présomption de non-conformité.</li>
      <li>Pays du Commonwealth : moins de lois que dans l'UE, mais mieux appliquées</li>
      <li>Taïwan : révolution des tournesols, utilisation de Pol.is</li>
      <li>Community notes sur Twitter : inspirant mais insatisfaisant (manipulables)</li>
      <li>Tournesol</li>
    </ul>
    <h3>II.3 Représentants algorithmiques</h3>
    <ul>
      <li>La prise de décision démocratique est coûteuse en temps et en effort cognitif humain. C'est d'autant plus problématique quand il faut prendre des décisions en temps limité.</li>
      <li>Solution : représentants algorithmiques ? Ex de WeBuildAI : les électeurs inscrivent leurs préférences dans un algo, qui vote quand il faut prendre une décision</li>
      <li>Actuellement : chaque citoyen peut fournir seulement quelques bits d'information par décennie (lors des élections). Les rep algo pourraient fournir bcp plus d'info. Pb : créer un rep algo nécessite une expertise technique, voire est impossible à faire à la main. Solution : machine learning pour apprendre les préférences des utilisateurs ?</li>
      <li>Pb : ces préférences ne sont pas cohérentes. Solution partielle : comparer des options plutôt que noter de façon absolue.</li>
      <li>Sur WeBuildAI et Tournesol, vote "creux" (seule une petite partie des contributeurs répond à chaque question). Pb : un contenu peut être défavorisé simplement parce qu'il attire des évaluateurs sévères. Le pb est atténué par les votes comparatifs. Autre problème : des contributeurs peuvent voter de façon plus tranchée que d'autres -> calibrage des scores sur Tournesol.</li>
      <li>Résilience Lipschitz : limiter l'impact que peut avoir un seul utilisateur.</li>
      <li>Tout ce qui précède : tentative de créer une philosophie morale calculable.</li>
    </ul>
    <h3>II.4 Droits de vote 2.0</h3>
    <ul>
      <li>Pb des faux comptes (aggravé par l'IA générative)</li>
      <li>Solution : carte d'identité numérique ?</li>
      <li>Les ZKP permettent de garantir la confidentialité.</li>
      <li>Épistocratie ?</li>
      <li>Démocratie liquide ?</li>
      <li>Plus généralement : réseaux de confiance (Wikipédia, Captain Fact,…). Ils sont sous-exploités car trop peu formalisés.</li>
      <li>Pb : les délégations peuvent être erronnées / biaisées. Solutions : ajuster la manière dont sont pris en compte les droits de vote, alerter les délégants, choisir ceux qui ont reçu le plus délégations venant de personnes ayant reçu beaucoup de délégations, mettre en place des "anti-délégations"</li>
      <li>Devoir de vigilance des délégués</li>
    </ul>
    <h3>II.5 Préférences vs volitions</h3>
    <ul>
      <li>Les IAR actuelles écoutent le système 1</li>
      <li>Mesures pour favoriser les volitions en démocratie classique : éducation, médias publics, interdiction de campagne le jour de l'élection. Autres idées : changer le mode de scrutin, convention citoyenne.</li>
      <li>Mesures pour favoriser les volitions sur les réseaux sociaux : rendre le partage plus difficile, community notes</li>
      <li>Demander l'explication des jugements ?</li>
      <li>Utiliser du Machine Learning pour apprendre les volitions ? On pourrait par exemple exploiter le temps de réflexion de l'utilisateur</li>
      <li>Constructivisme moral : une morale est satisfaisante si le processus qui a abouti à cette morale est satisfaisant ?</li>
    </ul>
    <h3>II.6 Écouter la majorité silencieuse</h3>
    <ul>
      <li>Ex du sondage de Musk pour le retour de Trump sur Twitter : problème d'expression inégale de la population</li>
      <li>Pb de l'évaluation des contenus : complexe et parfois traumatisant pour les humains</li>
      <li>Présomption de non-recommandabilité massive / seuls les contenus jugés recommandables par assez de comptes certifiés devraient pouvoir obtenir un droit d'amplification massif. Similaire aux revues par les pairs et aux rôles des rédacteurs en chefs.</li>
      <li>Donner de l'attention aux consensus (Pol.is, community notes)</li>
      <li>Pour corriger les biais d'activité : identifier les populations sous-représentées, démocratie liquide, vote bayésien (intégrer les votes probables des gens qui n'ont pas voté)</li>
      <li>Dilemme inclusion de la majorité silencieuse / sécurité du vote</li>
    </ul>
    <h3>II.7 Sécurité du vote</h3>
    <ul>
      <li>Utiliser les statistiques pour détecter un vote truqué (ex des élections russes de 2011)</li>
      <li>
        <p>Maths de la sécurité du vote :</p>
        <ul>
          <li>Anonymat : confidentialité différentielle</li>
          <li>Vote utile : théorie des scrutins</li>
          <li>Transparence : interprétabilité / explicabilité</li>
        </ul>
      </li>
      <li>Investir dans la sécurisation du scrutin (coût du cybercrime en 2023 : 4x le PIB de la France)</li>
      <li>Sobriété numérique ; à ce jour il faut voter physiquement</li>
      <li>Sandboxing : compartimenter les composants</li>
      <li>Redondance, systèmes zero-trust</li>
      <li>Ça reste un défi monumental et inter-disciplinaire</li>
    </ul>
    <h2>III Agir</h2>
    <h3>III.1 Naïveté et cynisme</h3>
    <ul>
      <li>Naïveté : syllogisme du politicien : quelque chose doit être fait, X est quelque chose, donc il faut faire X. => Il faut raisonner à l'échelle gloable, prendre en compte la difficulté de changer les comportements, éviter les œillères attentionnelles</li>
      <li>Cynisme éclairé : très tentant</li>
    </ul>
    <h3>III.2 Chaque dixième de degré compte</h3>
    <ul>
      <li>Ex de Picciolini, ex-néonazi qui alerte sur les dangers de la radicalisation</li>
      <li>Insuffisant ≠ inutile. Revoir nos ambitions à la baisse.</li>
      <li>Apporter du soutien est très efficace.</li>
      <li>Privilégier le court terme ?</li>
    </ul>
    <h3>III.3 La caisse à outils de l'humanité</h3>
    <ul>
      <li>Pol.is : permet de coordonner les discussions</li>
      <li>Créer des "possibles adjacents"</li>
      <li>Plus précisément : créer des "possibles adjacents" souhaitables (expérience de pensée des boules blanches et noires de Nick Bostrom)</li>
      <li>Impossible maintenant ≠ impossible toujours. On a déjà fait le plus dur pour créer un superorganisme sage.</li>
      <li>Préparer les bouleversements à venir : en cas d'urgence, s'il existe un plan d'action adéquant, il a de bonnes chances d'être considéré avec attention.</li>
    </ul>
    <h3>III.4 S'engager</h3>
    <ul>
      <li>Se former et former les autres (tenir compte de la psychologie)</li>
      <li>Contribuer à la recherche</li>
      <li>Favoriser les volitions, développer une "compassion rationnelle"</li>
      <li>Agir et lutter pour l'application des lois</li>
      <li>S'engager dans le mvt pour un numérique démocratique : Amnesty International, Mozilla, Algorithm Watch, Wikipedia, Tournesol,…</li>
      <li>Orienter sa carrière (accepter la sobriété financière)</li>
      <li>Faire des dons : Reporters Sans Frontières, Mozilla, Signal, Tournesol,…</li>
    </ul>
    <h3>III.5 Prendre soin de soi</h3>
    <ul>
      <li>Créer de la friction : désinstaller des applis, éloigner son smartphone, installer Focus Lock ou Forest,…</li>
      <li>Choisir une meilleure exposition informationnelle : régler ses notifications, éviter les IAR, plugin Tournesol,…</li>
      <li>Mieux comprendre sa psychologie : se renseigner et méditer</li>
      <li>Bien s'entourer</li>
      <li>Consulter un psychiatre si besoin</li>
    </ul>
  </body>
</html>
